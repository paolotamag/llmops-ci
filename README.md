# llmops-ci
When deploying LLM calls on raw conversation data, it is paramount to programmatically verify that the LLM calls are still returning expected results, following the principles of _continous integration (CI)_. 

In this repository, I demonstrate how to set this up using Langfuse (open source) and GitHub Actions. The small dataset (pet food customer service) interactions was generated by an LLM.

# llmops-ci
When deploying LLM calls on raw conversation data, it is paramount to programmatically verify that the LLM calls are still returning expected results, following the principles of _continous integration (CI)_. 

In this repository: 
- I demonstrate how to set this up using Langfuse (open source) and GitHub Actions. 
- The small dataset (pet food customer service) interactions was generated by an LLM.
- Using intent detection to trigger simple outcomes (like for example prepared answer) is a common approach in customer service, which got re-adapted recently to LLMs capabilities in several papers, for example [Arora et al (2024)](https://www.amazon.science/publications/intent-detection-in-the-age-of-llms).

